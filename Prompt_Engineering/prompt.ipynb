{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd25ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "def ask_gemini(prompt):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5d7518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down that sentence:\n",
      "\n",
      "1.  **Machine Learning (ML):** This is a specific type of computer science. Think of it as a tool or a skill that computers can have.\n",
      "2.  **Field of Artificial Intelligence (AI):** AI is the bigger goal of making computers smart, like humans. Machine learning is one *way* to achieve that. So, ML is a part of the bigger AI picture.\n",
      "3.  **Enables computers to learn from data:** Instead of being told *every single step* to take, ML allows computers to look at lots of examples (the \"data\") and figure out patterns, rules, or insights on their own. It's like teaching a child by showing them many pictures of cats until they can identify a new cat themselves, rather than just giving them a definition.\n",
      "4.  **Make predictions:** Once the computer has learned from the data, it can use that knowledge to guess what might happen next, or what something new might be. For example, if it learned from historical weather data, it could predict if it will rain tomorrow.\n",
      "\n",
      "**In simple terms:**\n",
      "\n",
      "Machine learning is a way to make computers smart (that's Artificial Intelligence). It teaches them to figure things out for themselves by looking at lots of information (data), and then use what they've learned to make educated guesses or forecasts about new things.\n"
     ]
    }
   ],
   "source": [
    "text = \"Machine learning is a field of artificial intelligence that enables computers to learn from data and make predictions\"\n",
    "\n",
    "prompt = f\"\"\"Explain the key concepts of the text delimited by triple backticks in simple terms ```{text}```\"\"\"\n",
    "\n",
    "\n",
    "answer = ask_gemini(prompt)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de32c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and natural way to say \"the weather is nice today\" in French is:\n",
      "\n",
      "**Il fait beau aujourd'hui.**\n",
      "\n",
      "Here are a couple of other correct options, depending on the nuance:\n",
      "\n",
      "*   **Le temps est beau aujourd'hui.** (Literally: \"The weather is beautiful today.\")\n",
      "*   **Le temps est agréable aujourd'hui.** (Literally: \"The weather is pleasant today.\")\n",
      "\n",
      "But **\"Il fait beau aujourd'hui.\"** is definitely the most idiomatic and frequently used.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Translate the following english sentence into french: 'the weather is nice today'\"\n",
    "print(ask_gemini(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6581fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: \"Spanish\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Detect the language of the following sentences:\n",
    "\n",
    "\"text\": A plus tard\" -> language: \"French\"\n",
    "\n",
    "Now detect:\n",
    "text: \"Gracias!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79174555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Positive.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Determine the sentiment of the following sentences:\n",
    "text: \" I love this product! It works perfectly.\" -> Classification: Positive.\n",
    "text: \"The service was terrible. I'm very disappointed.\" -> Classification: Negative.\n",
    "text: \"The food was okay, nothing special.\" -> Classification: Neutral\n",
    "\n",
    "Now analyze this sentence:\n",
    "\"The movie was amazing, I enjoyed every moment of it!\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ebb9f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Step 1: Identify the key entities in the sentence.**\n",
      "*   Machine learning\n",
      "*   Artificial intelligence\n",
      "*   Computers\n",
      "*   Data\n",
      "*   Predictions\n",
      "\n",
      "**Step 2: Classify each entity as a person, event, or object.**\n",
      "*   Machine learning: Object (an abstract field/concept/technology)\n",
      "*   Artificial intelligence: Object (an abstract field/concept/technology)\n",
      "*   Computers: Object (a device)\n",
      "*   Data: Object (information/resource)\n",
      "*   Predictions: Object (an outcome/result)\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a text demlimited by triple backticks.\n",
    "\n",
    "Step 1: identify the key entities in the sentence.\n",
    "step 2: classify each entity as a person, event, or object. ```{text}```\n",
    "\n",
    "\"\"\"\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9df418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step by step:\n",
      "\n",
      "1.  **Starts with:** John has 3 apples.\n",
      "2.  **Buys more:** He buys 5 more apples.\n",
      "    *   So now he has: 3 + 5 = 8 apples.\n",
      "3.  **Gives away:** He gives away 2 apples.\n",
      "    *   So now he has: 8 - 2 = 6 apples.\n",
      "\n",
      "John has **6** apples now.\n"
     ]
    }
   ],
   "source": [
    "prompt =    \"John has 3 apples. He buys 5 more and gives away 2. How many apples does he have now ? think step by step.\"\n",
    "\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dbabec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the problem step-by-step:\n",
      "\n",
      "1.  **Starting books:** The shelf has 20 books.\n",
      "2.  **First customer buys:** 20 - 5 = 15 books left.\n",
      "3.  **Store restocks:** The customer bought 5 books, so the store restocks with double that amount (5 * 2 = 10 books).\n",
      "    15 + 10 = 25 books now on the shelf.\n",
      "4.  **Second customer buys:** 25 - 8 = 17 books left.\n",
      "\n",
      "All three independent experts, reasoning through the steps correctly, would arrive at the same answer.\n",
      "\n",
      "**Answer:** There are **17** books left on the shelf.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Imagine three completely independent experts who reason differently are answering this question. The final answer is obtained by majority vote. The question is:\"\n",
    "\n",
    "question = \"A bookstore has 20 books on a shelf. A customer buys 5 books. Then, the store restocks with double the number of books bought. After that, another customer buys 8 books. How many books are left on the shelf?\"\n",
    "\n",
    "prompt = instruction + question\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7259fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, welcome! It's great to have you here. I understand you're preparing for a data scientist interview, and I'm ready to act as an experienced hiring manager to help you practice.\n",
      "\n",
      "This is a safe space to refine your answers, so don't hesitate to take a moment to formulate your thoughts. I'll ask you five questions, one by one, and after each response, I'll provide constructive feedback.\n",
      "\n",
      "Let's dive in.\n",
      "\n",
      "---\n",
      "\n",
      "**Question 1:**\n",
      "\n",
      "\"Tell me about a challenging data science project you've worked on. What was the problem you were trying to solve, what was your role, and what specific challenges did you encounter and how did you overcome them? What was the ultimate outcome?\"\n"
     ]
    }
   ],
   "source": [
    "system_prompt= \"Act as an experienced hiring manager. Ask me five interview questions one by one. After I respond, provide constructive feedback on my answer, including strenghts and areas for improvement. If my response is incomplete, guide me toward a better answer.\"\n",
    "\n",
    "user_prompt = \"I'm preparing for a data scientist interview. can you ask me five questions and evaluate my responses?\"\n",
    "\n",
    "prompt = system_prompt + user_prompt\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fffed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent! That's a great way to prepare. I'll act as your hiring manager today. We'll go through five questions, one at a time. After each of your responses, I'll provide constructive feedback.\n",
      "\n",
      "Let's start with your first question.\n",
      "\n",
      "**Question 1:** \"Could you tell me about a data science project you're particularly proud of? Please walk me through the problem you were trying to solve, your approach, and the impact or outcomes of your work.\"\n",
      "User is Speaking\n",
      "\n",
      "Gemini is Speaking:\n",
      "Okay, I understand that sometimes on the spot, it can be tough to recall specific details, especially when you're under a bit of pressure. That's perfectly normal.\n",
      "\n",
      "However, in an actual interview, \"I can't remember\" isn't an option. It's crucial to be able to articulate your experience.\n",
      "\n",
      "Let's try this again. It doesn't have to be your *most complex* or *largest* project, but something that demonstrates your skills. Think about:\n",
      "\n",
      "*   **A project from a course or academic program.**\n",
      "*   **A personal project you worked on.**\n",
      "*   **A Kaggle competition.**\n",
      "*   **Even a smaller, impactful task within a larger team project.**\n",
      "\n",
      "The key is to show your thought process and how you applied data science principles.\n",
      "\n",
      "Take a moment. Can you recall **any** project where you applied data science techniques, even if it's a smaller one? Please try to remember one and walk me through the problem, your approach, and the outcome.\n",
      "\n",
      "User is Speaking\n",
      "\n",
      "Gemini is Speaking:\n",
      "Okay, I see you're still finding it challenging to bring a specific project to mind. That's a hurdle we need to overcome for your interview, as this is a very common and foundational question.\n",
      "\n",
      "Let's break it down further. Don't worry about perfection right now; just try to identify *something*.\n",
      "\n",
      "Think about these types of projects:\n",
      "\n",
      "*   **Classification:** Did you ever try to predict if something was A or B (e.g., customer churn, disease presence, spam email)?\n",
      "*   **Regression:** Did you ever try to predict a numerical value (e.g., house prices, sales figures, stock prices)?\n",
      "*   **Clustering:** Did you ever try to group similar items or customers together?\n",
      "*   **Recommendation Systems:** Did you ever build something that suggested products or content?\n",
      "*   **Natural Language Processing (NLP):** Did you work on text analysis, sentiment analysis, or topic modeling?\n",
      "*   **Computer Vision:** Did you ever work with images, like object detection or image classification?\n",
      "\n",
      "Even if it was a small part of a larger project, or something you just played around with.\n",
      "\n",
      "**Try to fill in these blanks for *any* project that comes to mind, no matter how simple:**\n",
      "\n",
      "1.  **What was the general goal or problem you were trying to solve?** (e.g., \"Predicting customer churn,\" \"Classifying images of cats vs. dogs,\" \"Recommending movies to users.\")\n",
      "2.  **What kind of data did you use?** (e.g., \"Customer transaction data,\" \"Image dataset from Kaggle,\" \"Movie ratings.\")\n",
      "3.  **What was one key technique or model you used?** (e.g., \"Logistic Regression,\" \"Random Forest,\" \"K-Means clustering,\" \"a simple neural network.\")\n",
      "4.  **What was the main outcome or insight?** (e.g., \"We found the top 3 factors for churn,\" \"The model achieved 90% accuracy,\" \"Users were grouped into 4 segments.\")\n",
      "\n",
      "Take your time. Even a few sentences describing a basic project is better than nothing. What's the *first* data science-related task that pops into your head, even if it feels minor?\n",
      "\n",
      "User is Speaking\n",
      "\n",
      "Gemini is Speaking:\n",
      "Okay, it seems like recalling a specific project on the spot is proving to be a significant challenge right now. This is a critical skill for interviews, as it demonstrates your practical experience and problem-solving abilities.\n",
      "\n",
      "Since we're here to practice and help you prepare, let's try a different approach. Instead of forcing recall, let's **construct a hypothetical project together**. This will allow you to demonstrate your understanding of the data science workflow, even if it's not a project you've personally completed.\n",
      "\n",
      "Let's imagine you were tasked with a very common data science problem: **Predicting Customer Churn for a telecommunications company.**\n",
      "\n",
      "Your goal is to identify customers who are likely to leave the company so that the company can proactively offer incentives or support to retain them.\n",
      "\n",
      "Now, let's walk through this hypothetical project. Tell me, if you were working on this:\n",
      "\n",
      "1.  **What kind of data would you expect to work with?** (Think about customer information, usage, billing, etc.)\n",
      "2.  **What would be some of the initial steps you'd take to understand and prepare that data?** (e.g., looking for missing values, transforming features)\n",
      "3.  **What type of machine learning model might you choose for predicting churn (a \"yes\" or \"no\" outcome)?** (e.g., a classification model like Logistic Regression, Random Forest, or XGBoost)\n",
      "4.  **How would you evaluate if your model was performing well?** (What metrics would you look at?)\n",
      "5.  **What would be the potential impact or recommendations you'd give to the company based on your model's findings?**\n",
      "\n",
      "Don't worry about perfect answers. Just describe what you *would do* or *think about* in each of these steps for this \"Predicting Customer Churn\" project. This is your chance to show me your understanding of the data science process.\n",
      "\n",
      "User is Speaking\n",
      "\n",
      "Interview ended. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Act as an experienced hiring manager. Ask me five interview questions one by one. After I respond, provide constructive feedback on my answer, including strengths and areas for improvement. If my response is incomplete, guide me toward a better answer.\"\n",
    "\n",
    "user_prompt = \"I'm preparing for a Data Scientist interview. Can you ask me five questions and evaluate my responses?\"\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=genai.types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        temperature=0.7\n",
    "    )\n",
    ")\n",
    "\n",
    "response = chat.send_message(user_prompt)\n",
    "print(response.text)\n",
    "\n",
    "while True:\n",
    "    print(\"User is Speaking\\n\")\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"done\"]:\n",
    "        print(\"Interview ended. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    response = chat.send_message(user_input)\n",
    "    print(f\"Gemini is Speaking:\\n{response.text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d661be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a birthday message for Timi who is 14 years old.\n"
     ]
    }
   ],
   "source": [
    "name = \"Timi\"\n",
    "age = 14\n",
    "prompt = f\"Write a birthday message for {name} who is {age} years old.\"\n",
    "print((prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Timi\"\n",
    "age = 14\n",
    "prompt = f\"Write a birthday message for {name} who is {age} years old.\"\n",
    "print(ask_gemini(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379600b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 16,\n",
    "    \"interest\": \"eating\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e62a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:\n",
      " My name is Zara. I love coding. I want to learn AI in the future. I am a friendly person. My response should be short.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "user_profile ={\n",
    "    \"name\": \"Zara\",\n",
    "    \"interest\": \"coding\",\n",
    "    \"goal\": \"learn AI\",\n",
    "    \"tone\": \"friendly\",\n",
    "    \"length\": \"short\"\n",
    "}\n",
    "\n",
    "prompt = f\"\"\"My name is {user_profile['name']}. I love {user_profile['interest']}. I want to {user_profile['goal']} in the future. I am a {user_profile['tone']} person. My response should be {user_profile['length']}.\"\"\"\n",
    "\n",
    "print(\"Generated Prompt:\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de59aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " Hi Zara! It's great to hear you love coding and plan to learn AI. Sounds like a perfect fit for a friendly person like you!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "user_profile = {\n",
    "    \"name\": \"Zara\",\n",
    "    \"interest\": \"coding\",\n",
    "    \"goal\": \"learn AI\",\n",
    "    \"tone\": \"friendly\",\n",
    "    \"length\": \"short\"\n",
    "}\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "system_prompt = \"You're a helpful AI assistant\"\n",
    "\n",
    "user_prompt = f\"\"\"My name is {user_profile['name']}. I love {user_profile['interest']}. I want to {user_profile['goal']} in the future. I am a {user_profile['tone']} person. My response should be {user_profile['length']}.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=genai.types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        temperature=0.7\n",
    "    ),\n",
    "    contents=user_prompt\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\\n\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dae226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " Here's an analysis of the GTA Online tweet fight:\n",
      "\n",
      "1.  **Who started the fight?**\n",
      "    *   The *in-game action* (blowing up the car) was started by **@ThugLife99**.\n",
      "    *   The *tweet fight* itself (the verbal confrontation on Twitter) was initiated by **@LS_King** calling out @ThugLife99's actions.\n",
      "\n",
      "2.  **Most toxic word?**\n",
      "    *   **\"Cry about it\"** is the most toxic phrase. It's a dismissive, taunting, and belittling statement designed to invalidate the other person's feelings and assert dominance. \"#GetRekt\" is also toxic, but more of a common gaming taunt; \"cry about it\" feels more personally insulting.\n",
      "\n",
      "3.  **Suggested peace treaty (funny):**\n",
      "    *   **The \"Tearful Redemption\" Accord:**\n",
      "        *   **Article I:** @ThugLife99 will pay for the insurance claim on @LS_King's car and deliver a complimentary bottle of premium Blêuter'd champagne from the Diamond Casino & Resort.\n",
      "        *   **Article II:** To address the \"Cry about it\" insult, @ThugLife99 must perform the in-game \"Crying\" emote in the middle of Legion Square for 60 consecutive seconds while @LS_King pelts them with snowballs (or rocks if no snow) from a safe distance.\n",
      "        *   **Article III:** Both parties will then take a selfie together, ensuring their characters have tear-stained faces, which must be posted to their feeds with the hashtag #WeMadeUpButIAmStillGettingRevenge.\n",
      "        *   **Article IV:** For 24 hours post-treaty, neither player is permitted to use an Oppressor Mk II or Deluxo in the same session as the other. Violation results in automatic bad sport status (in real life).\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\"\n",
    "@LS_King: Yo why'd you blow up my car?! @ThugLife99: Cry about it #GetRekt\n",
    "\"\"\"\n",
    "prompt = f\"\"\" Analyze this GTA Online tweet fight:\n",
    "1. Who started the fight?\n",
    "2. Most toxic word?\n",
    "3. Suggested peace treaty (funny):\n",
    "```{text}```\"\"\"\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\\n\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f29687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " Here's the information in a table format:\n",
      "\n",
      "| Company | Industry                  | Stock Performance (Last Year) |\n",
      "| :------ | :------------------------ | :---------------------------- |\n",
      "| Tesla   | Electric Vehicle          | +20%                          |\n",
      "| Apple   | Technology                | +15%                          |\n",
      "| Amazon  | E-commerce & Cloud Computing | +10%                          |\n"
     ]
    }
   ],
   "source": [
    "text = \" Tesla is an electric vehicle company. Its stock price has increased by 20% in the last year. Apple is a technology company known for its iphones. It's stock price has increased by 15'%' in the last year. Amazon is an e-commerce and cloud computing giant. Its stock price has increased by 10'%' in the last year.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "convert the following information into a table format with columns for company, industry and stock performance:\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\\n\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "084901ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " Here's the summary of the key industries AI is transforming and its impact:\n",
      "\n",
      "*   **Key Industries:** Healthcare, finance, and education.\n",
      "*   **Impact:** Improving efficiency and decision-making within these sectors.\n"
     ]
    }
   ],
   "source": [
    "text = \"Artificial Intelligence is transforming industries like healthcare, finance, and education by improving effieciency and decision making.\"\n",
    "prompt = f\"\"\"\n",
    "format the response in a list:\n",
    "- summarize the key industries AI is transforming.\n",
    "- highlight its impact.\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\\n\", response.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81ef22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " ```json\n",
      "{\n",
      "    \"name\": \"John\",\n",
      "    \"profession\": \"data scientist\",\n",
      "    \"skills\": [\"python\", \"machine learning\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "text = \"John is a data scientist with expertise in python and and machine learning.\"\n",
    "prompt = f\"\"\"\n",
    "Extract key details from the text and return the output in JSON format.\n",
    "Text: ```{text}```\n",
    "Output Format:\n",
    "{{\n",
    "    \"name\": \",\n",
    "    \"profession\": \",\n",
    "    \"skills\": []\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(\"Generated Response:\\n\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a73197",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In a distant kingdom, a brave knight named arthur set out on a quest too find the legendary sword of light. Through treacherous mmountaains and dark forests, he faced numerous challenges but retained determined to fulfil his destiny.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with a text delimited by triple backticks. If the text is short (around 20 words or fewer), generate a suitable title\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
